{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;35mgenerated_molecules_CN.png\u001b[0m  RLfinetune.py        tokenize_smiles.py\n",
      "generated_smiles_CN.smi     RL+LSTM_model.ipynb  train_model.py\n",
      "preprocess.py               testRLLSTM.py\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdkit in /home/satya/miniconda3/lib/python3.10/site-packages (2024.9.6)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: numpy in /home/satya/miniconda3/lib/python3.10/site-packages (2.2.4)\n",
      "Requirement already satisfied: pandas in /home/satya/miniconda3/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /home/satya/miniconda3/lib/python3.10/site-packages (3.10.1)\n",
      "Requirement already satisfied: Pillow in /home/satya/miniconda3/lib/python3.10/site-packages (from rdkit) (11.1.0)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /home/satya/miniconda3/lib/python3.10/site-packages (from tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Using cached protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/satya/miniconda3/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/satya/miniconda3/lib/python3.10/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/satya/miniconda3/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/satya/miniconda3/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Using cached keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/satya/miniconda3/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/satya/miniconda3/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/satya/miniconda3/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/satya/miniconda3/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/satya/miniconda3/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/satya/miniconda3/lib/python3.10/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/satya/miniconda3/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/satya/miniconda3/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/satya/miniconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/satya/miniconda3/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/satya/miniconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/satya/miniconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/satya/miniconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/satya/miniconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/satya/miniconda3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/satya/miniconda3/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/satya/miniconda3/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/satya/miniconda3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.8/644.8 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "Downloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (397 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, h5py, keras, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.4\n",
      "    Uninstalling numpy-2.2.4:\n",
      "      Successfully uninstalled numpy-2.2.4\n",
      "Successfully installed absl-py-2.2.2 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 keras-3.9.2 libclang-18.1.1 markdown-3.7 ml-dtypes-0.5.1 namex-0.0.8 numpy-2.1.3 opt-einsum-3.4.0 optree-0.15.0 protobuf-5.29.4 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.0.1 werkzeug-3.1.3 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rdkit tensorflow numpy pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to: /home/satya/Desktop/BI/processed_data/CCAB.smi\n"
     ]
    }
   ],
   "source": [
    "!python preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:📂 Loading and tokenizing SMILES from /home/satya/Desktop/BI/processed_data/CCAB.smi\n",
      "INFO:__main__:✅ Loaded 68802 valid SMILES\n",
      "INFO:__main__:💾 Tokenized SMILES saved to: /home/satya/Desktop/BI/processed_data/tokenized_data.pkl\n",
      "INFO:__main__:🔍 Sample tokenized SMILES:\n",
      "SMILES 1: ['C', '[C@H]', '1', 'C', 'C', 'C', '[C@H]', '1', 'N', 'C', '(', '=', 'O', ')', 'C', '(', '=', 'O', ')', 'N', 'c', '1', 'c', 'c', 'n', '(', 'C', ')', 'n', '1']\n",
      "SMILES 2: ['C', 'C', '(', '=', 'O', ')', 'N', 'c', '1', 'c', 'c', 'c', '(', 'S', '(', '=', 'O', ')', '(', '=', 'O', ')', 'N', '(', 'C', ')', 'C', 'C', 'O', ')', 'c', 'c', '1']\n",
      "SMILES 3: ['C', 'C', 'O', 'c', '1', 'c', 'c', 'c', '(', '-', 'n', '2', 'n', 'n', 'n', 'c', '2', 'S', 'C', 'C', '(', 'N', ')', '=', 'O', ')', 'c', 'c', '1']\n",
      "SMILES 4: ['C', 'N', 'C', '(', '=', 'O', ')', 'N', '[C@@H]', '1', 'N', '(', 'C', ')', 'C', '(', '=', 'O', ')', 'N', '[C@H]', '(', 'C', '(', 'C', ')', 'C', ')', 'C', '1', '(', 'C', ')', 'C']\n",
      "SMILES 5: ['C', 'C', 'C', 'C', '[C@H]', '(', 'N', ')', 'C', '(', '=', 'O', ')', 'N', '[C@H]', '(', 'C', 'C', 'S', 'C', ')', 'C', '(', 'N', ')', '=', 'O']\n"
     ]
    }
   ],
   "source": [
    "!python tokenize_smiles.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-10 03:48:39.397333: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744237119.412839   34929 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744237119.417523   34929 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744237119.429361   34929 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744237119.429403   34929 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744237119.429407   34929 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744237119.429409   34929 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "/home/satya/miniconda3/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1744237122.437461   34929 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4280 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "Epoch 1/50\n",
      "I0000 00:00:1744237126.701640   35071 cuda_dnn.cc:529] Loaded cuDNN version 90800\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6134 - loss: 1.3117 - val_accuracy: 0.7920 - val_loss: 0.6078\n",
      "Epoch 2/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8033 - loss: 0.5737 - val_accuracy: 0.8210 - val_loss: 0.5151\n",
      "Epoch 3/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8251 - loss: 0.4993 - val_accuracy: 0.8326 - val_loss: 0.4783\n",
      "Epoch 4/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8368 - loss: 0.4626 - val_accuracy: 0.8396 - val_loss: 0.4534\n",
      "Epoch 5/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8443 - loss: 0.4386 - val_accuracy: 0.8450 - val_loss: 0.4373\n",
      "Epoch 6/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8504 - loss: 0.4189 - val_accuracy: 0.8486 - val_loss: 0.4234\n",
      "Epoch 7/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8552 - loss: 0.4043 - val_accuracy: 0.8517 - val_loss: 0.4141\n",
      "Epoch 8/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8595 - loss: 0.3903 - val_accuracy: 0.8545 - val_loss: 0.4073\n",
      "Epoch 9/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8630 - loss: 0.3794 - val_accuracy: 0.8565 - val_loss: 0.3980\n",
      "Epoch 10/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8659 - loss: 0.3698 - val_accuracy: 0.8582 - val_loss: 0.3919\n",
      "Epoch 11/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8689 - loss: 0.3599 - val_accuracy: 0.8597 - val_loss: 0.3875\n",
      "Epoch 12/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8714 - loss: 0.3526 - val_accuracy: 0.8627 - val_loss: 0.3825\n",
      "Epoch 13/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8736 - loss: 0.3455 - val_accuracy: 0.8632 - val_loss: 0.3800\n",
      "Epoch 14/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8753 - loss: 0.3396 - val_accuracy: 0.8645 - val_loss: 0.3768\n",
      "Epoch 15/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8776 - loss: 0.3332 - val_accuracy: 0.8650 - val_loss: 0.3755\n",
      "Epoch 16/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8792 - loss: 0.3283 - val_accuracy: 0.8648 - val_loss: 0.3747\n",
      "Epoch 17/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8806 - loss: 0.3230 - val_accuracy: 0.8670 - val_loss: 0.3697\n",
      "Epoch 18/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8819 - loss: 0.3192 - val_accuracy: 0.8670 - val_loss: 0.3702\n",
      "Epoch 19/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8834 - loss: 0.3146 - val_accuracy: 0.8671 - val_loss: 0.3692\n",
      "Epoch 20/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8845 - loss: 0.3114 - val_accuracy: 0.8682 - val_loss: 0.3676\n",
      "Epoch 21/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8857 - loss: 0.3083 - val_accuracy: 0.8682 - val_loss: 0.3677\n",
      "Epoch 22/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8865 - loss: 0.3049 - val_accuracy: 0.8672 - val_loss: 0.3671\n",
      "Epoch 23/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8872 - loss: 0.3029 - val_accuracy: 0.8682 - val_loss: 0.3669\n",
      "Epoch 24/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8881 - loss: 0.3002 - val_accuracy: 0.8692 - val_loss: 0.3654\n",
      "Epoch 25/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8890 - loss: 0.2972 - val_accuracy: 0.8698 - val_loss: 0.3672\n",
      "Epoch 26/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8897 - loss: 0.2949 - val_accuracy: 0.8698 - val_loss: 0.3657\n",
      "Epoch 27/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8904 - loss: 0.2933 - val_accuracy: 0.8696 - val_loss: 0.3664\n",
      "Epoch 28/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8909 - loss: 0.2911 - val_accuracy: 0.8699 - val_loss: 0.3646\n",
      "Epoch 29/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8912 - loss: 0.2897 - val_accuracy: 0.8699 - val_loss: 0.3669\n",
      "Epoch 30/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8919 - loss: 0.2883 - val_accuracy: 0.8710 - val_loss: 0.3664\n",
      "Epoch 31/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8922 - loss: 0.2867 - val_accuracy: 0.8714 - val_loss: 0.3662\n",
      "Epoch 32/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8927 - loss: 0.2848 - val_accuracy: 0.8712 - val_loss: 0.3670\n",
      "Epoch 33/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8932 - loss: 0.2838 - val_accuracy: 0.8714 - val_loss: 0.3659\n",
      "Epoch 34/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8937 - loss: 0.2820 - val_accuracy: 0.8715 - val_loss: 0.3664\n",
      "Epoch 35/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8938 - loss: 0.2811 - val_accuracy: 0.8718 - val_loss: 0.3665\n",
      "Epoch 36/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8938 - loss: 0.2809 - val_accuracy: 0.8710 - val_loss: 0.3685\n",
      "Epoch 37/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8945 - loss: 0.2797 - val_accuracy: 0.8713 - val_loss: 0.3684\n",
      "Epoch 38/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8948 - loss: 0.2781 - val_accuracy: 0.8720 - val_loss: 0.3684\n",
      "Epoch 39/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8952 - loss: 0.2773 - val_accuracy: 0.8716 - val_loss: 0.3687\n",
      "Epoch 40/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8953 - loss: 0.2766 - val_accuracy: 0.8716 - val_loss: 0.3690\n",
      "Epoch 41/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8953 - loss: 0.2756 - val_accuracy: 0.8712 - val_loss: 0.3704\n",
      "Epoch 42/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8956 - loss: 0.2755 - val_accuracy: 0.8713 - val_loss: 0.3695\n",
      "Epoch 43/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8960 - loss: 0.2740 - val_accuracy: 0.8716 - val_loss: 0.3698\n",
      "Epoch 44/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8964 - loss: 0.2738 - val_accuracy: 0.8721 - val_loss: 0.3706\n",
      "Epoch 45/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8963 - loss: 0.2736 - val_accuracy: 0.8720 - val_loss: 0.3710\n",
      "Epoch 46/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8966 - loss: 0.2724 - val_accuracy: 0.8717 - val_loss: 0.3723\n",
      "Epoch 47/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8969 - loss: 0.2715 - val_accuracy: 0.8720 - val_loss: 0.3716\n",
      "Epoch 48/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8970 - loss: 0.2711 - val_accuracy: 0.8717 - val_loss: 0.3712\n",
      "Epoch 49/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8970 - loss: 0.2709 - val_accuracy: 0.8729 - val_loss: 0.3714\n",
      "Epoch 50/50\n",
      "\u001b[1m968/968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8975 - loss: 0.2698 - val_accuracy: 0.8718 - val_loss: 0.3715\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "✅ Model saved at /home/satya/Desktop/BI/saved_model/Orig/lstm_generator.h5\n"
     ]
    }
   ],
   "source": [
    "!python train_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-10 03:55:00.371882: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744237500.390491   47035 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744237500.396066   47035 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744237500.411555   47035 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744237500.411587   47035 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744237500.411589   47035 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744237500.411592   47035 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "I0000 00:00:1744237503.238288   47035 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4280 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "I0000 00:00:1744237504.990669   47246 cuda_dnn.cc:529] Loaded cuDNN version 90800\n",
      "[Ep 0]🎯Reward:3.75|Loss:-1.1404|💊SMILES: Cc1cc(C(=O)NCCn2nnc3ccccc3c2=O)no1\n",
      "🎯Total Reward Accumulated: 3.7530\n",
      "[Ep 1]🎯Reward:3.81|Loss:-1.1623|💊SMILES: CC(C)N1C[C@H](C)[C@H](NS(=O)(=O)[C@H]2CCOC2)C1\n",
      "🎯Total Reward Accumulated: 7.5615\n",
      "[03:55:10] Can't kekulize mol.  Unkekulized atoms: 9\n",
      "[Ep 2]🎯Reward:0.00|Loss:0.0000|💊SMILES: CC(C)C[C@](C)(NC(=O)c1cn2cccnc2)C(=O)N1\n",
      "🎯Total Reward Accumulated: 7.5615\n",
      "[Ep 3]🎯Reward:4.81|Loss:-1.5406|💊SMILES: CNC(=O)[C@H]1CC(c2ccc(OCCN(C)C)nc2)=N1\n",
      "🎯Total Reward Accumulated: 12.3743\n",
      "[03:55:13] SMILES Parse Error: unclosed ring for input: 'Cc1nn(C)c2S(=O)(=O)N[C@@H]1CCN[C@@H]1C'\n",
      "[Ep 4]🎯Reward:0.00|Loss:0.0000|💊SMILES: Cc1nn(C)c2S(=O)(=O)N[C@@H]1CCN[C@@H]1C\n",
      "🎯Total Reward Accumulated: 12.3743\n",
      "[Ep 5]🎯Reward:4.52|Loss:-1.4707|💊SMILES: CC(=O)OC[C@@H]1O[C@@H](OC(C)=O)C[C@@H]1OC=C\n",
      "🎯Total Reward Accumulated: 16.8992\n",
      "[03:55:16] SMILES Parse Error: unclosed ring for input: 'Cc1ccnc2nc(C(=O)Nc3ccc(CNC(N)=O)cc3)n1'\n",
      "[Ep 6]🎯Reward:0.00|Loss:0.0000|💊SMILES: Cc1ccnc2nc(C(=O)Nc3ccc(CNC(N)=O)cc3)n1\n",
      "🎯Total Reward Accumulated: 16.8992\n",
      "[Ep 7]🎯Reward:3.84|Loss:-1.2785|💊SMILES: COc1cccc(OCC(=O)Nc2n[nH]c(C)n2)c1\n",
      "🎯Total Reward Accumulated: 20.7422\n",
      "[Ep 8]🎯Reward:4.90|Loss:-1.5233|💊SMILES: Cc1cscc1C(=O)N1CCN(C[C@@H](C)O)CC1\n",
      "🎯Total Reward Accumulated: 25.6377\n",
      "[Ep 9]🎯Reward:3.78|Loss:-0.8145|💊SMILES: COC(=O)C[C@H](NC(=O)c1ccccc1)C(=O)OC\n",
      "🎯Total Reward Accumulated: 29.4225\n",
      "[Ep 10]🎯Reward:3.68|Loss:-1.2261|💊SMILES: COc1ccc(OCC(=O)N[C@H](COC)C(N)=O)cc1\n",
      "🎯Total Reward Accumulated: 33.1036\n",
      "[Ep 11]🎯Reward:3.69|Loss:-0.9275|💊SMILES: Cc1cccc(C)c1NC(=O)C(=O)NCC(O)C\n",
      "🎯Total Reward Accumulated: 36.7958\n",
      "[Ep 12]🎯Reward:3.75|Loss:-1.0338|💊SMILES: COCC(=O)N1CC[C@@H](Oc2cc(OC)ncn2)C1\n",
      "🎯Total Reward Accumulated: 40.5495\n",
      "[Ep 13]🎯Reward:4.67|Loss:-1.1668|💊SMILES: CC[C@@H](O)CCNS(=O)(=O)C[C@H]1CCOC1\n",
      "🎯Total Reward Accumulated: 45.2223\n",
      "[Ep 14]🎯Reward:3.63|Loss:-1.2341|💊SMILES: CCCn1nnnc1NC(=O)CSc1nc(C)cc(C)n1\n",
      "🎯Total Reward Accumulated: 48.8548\n",
      "[Ep 15]🎯Reward:3.84|Loss:-1.2306|💊SMILES: CCS(=O)(=O)C[C@H](C)n1cc(Br)cn1\n",
      "🎯Total Reward Accumulated: 52.6975\n",
      "[Ep 16]🎯Reward:4.82|Loss:-1.1186|💊SMILES: CN(Cc1nnc2n1CCC2)C(=O)c1ccccn1\n",
      "🎯Total Reward Accumulated: 57.5164\n",
      "[Ep 17]🎯Reward:4.78|Loss:-1.1608|💊SMILES: CN1CCO[C@@H](C(=O)N2CCOC[C@H]2c2cccn2C)C1\n",
      "🎯Total Reward Accumulated: 62.3008\n",
      "[Ep 18]🎯Reward:3.87|Loss:-0.8736|💊SMILES: CCc1nnc2n1C[C@H](NC(=O)c1cnccn1)CC2\n",
      "🎯Total Reward Accumulated: 66.1733\n",
      "[Ep 19]🎯Reward:4.78|Loss:-1.3645|💊SMILES: Cc1ccccc1CC(=O)N(C[C@H]1CC[C@@H](O)[C@@H]1O)C(=O)O\n",
      "🎯Total Reward Accumulated: 70.9488\n",
      "[Ep 20]🎯Reward:4.72|Loss:-1.4226|💊SMILES: CSCCC(=O)N1CCCC[C@H]1CNC(=O)CN\n",
      "🎯Total Reward Accumulated: 75.6734\n",
      "[Ep 21]🎯Reward:3.64|Loss:-1.4230|💊SMILES: CCOCCO[C@@H](C)C(=O)N[C@H]1CCC[C@H](OC)[C@H]1O\n",
      "🎯Total Reward Accumulated: 79.3087\n",
      "[Ep 22]🎯Reward:4.76|Loss:-1.0265|💊SMILES: CC(=O)NCCNS(=O)(=O)c1cc(F)cc(F)c1\n",
      "🎯Total Reward Accumulated: 84.0733\n",
      "[Ep 23]🎯Reward:4.67|Loss:-1.5870|💊SMILES: CC(C)c1nccn1CC(=O)N[C@@H](C(=O)O)[C@@H](C)O\n",
      "🎯Total Reward Accumulated: 88.7450\n",
      "[Ep 24]🎯Reward:3.73|Loss:-1.2505|💊SMILES: CCOCC(=O)N1CC[C@@H]2COC[C@]2(C(=O)N(C)C)C1\n",
      "🎯Total Reward Accumulated: 92.4726\n",
      "[Ep 25]🎯Reward:4.83|Loss:-1.4622|💊SMILES: COCc1cncc2c1CCN(C(=O)CN)CC2\n",
      "🎯Total Reward Accumulated: 97.2981\n",
      "[Ep 26]🎯Reward:4.53|Loss:-1.8982|💊SMILES: CN(CC1(O)CCCCC1)[C@H](O)CSc1ncn[nH]1\n",
      "🎯Total Reward Accumulated: 101.8288\n",
      "[03:55:46] Can't kekulize mol.  Unkekulized atoms: 1 2 4\n",
      "[Ep 27]🎯Reward:0.00|Loss:0.0000|💊SMILES: Cc1noc(Cc2ccc(NC(=O)C(N)=O)cc2)c1=O\n",
      "🎯Total Reward Accumulated: 101.8288\n",
      "[Ep 28]🎯Reward:4.74|Loss:-1.2266|💊SMILES: COCCNC(=O)c1cc(N2CCOCC2)on1\n",
      "🎯Total Reward Accumulated: 106.5684\n",
      "[Ep 29]🎯Reward:4.85|Loss:-0.9807|💊SMILES: CN1CCN(S(=O)(=O)c2cncc(Cl)c2O)CC1\n",
      "🎯Total Reward Accumulated: 111.4209\n",
      "[Ep 30]🎯Reward:3.79|Loss:-0.9440|💊SMILES: CC(=O)N(C1CC1)[C@H]1CC[C@@H](NC(=O)[C@H](C)N)CC1\n",
      "🎯Total Reward Accumulated: 115.2107\n",
      "[03:55:52] SMILES Parse Error: syntax error while parsing: C[S@@]1(=O)=CC(23)[C@H]2[C@H]4CCO[C@]3(COC(C)(C))C(=O)[C@@H]13\n",
      "[03:55:52] SMILES Parse Error: check for mistakes around position 16:\n",
      "[03:55:52] C[S@@]1(=O)=CC(23)[C@H]2[C@H]4CCO[C@]3(CO\n",
      "[03:55:52] ~~~~~~~~~~~~~~~^\n",
      "[03:55:52] SMILES Parse Error: Failed parsing SMILES 'C[S@@]1(=O)=CC(23)[C@H]2[C@H]4CCO[C@]3(COC(C)(C))C(=O)[C@@H]13' for input: 'C[S@@]1(=O)=CC(23)[C@H]2[C@H]4CCO[C@]3(COC(C)(C))C(=O)[C@@H]13'\n",
      "[Ep 31]🎯Reward:0.00|Loss:0.0000|💊SMILES: C[S@@]1(=O)=CC(23)[C@H]2[C@H]4CCO[C@]3(COC(C)(C))C(=O)[C@@H]13\n",
      "🎯Total Reward Accumulated: 115.2107\n",
      "[Ep 32]🎯Reward:4.83|Loss:-1.6088|💊SMILES: Cc1ccc2c(c1)N[C@@H](C(=O)O)CN(S(C)(=O)=O)C2\n",
      "🎯Total Reward Accumulated: 120.0424\n",
      "[Ep 33]🎯Reward:3.85|Loss:-0.8729|💊SMILES: Cc1csc(=O)n1CCC(=O)Nc1cn[nH]c1\n",
      "🎯Total Reward Accumulated: 123.8930\n",
      "[Ep 34]🎯Reward:4.85|Loss:-1.0245|💊SMILES: CN(C)S(=O)(=O)NCCN1CCc2ccccc2C1\n",
      "🎯Total Reward Accumulated: 128.7460\n",
      "[Ep 35]🎯Reward:4.89|Loss:-1.1634|💊SMILES: Cc1nc(N)cc([C@H]2CN(Cc3cnn(C)c3)CCO2)n1\n",
      "🎯Total Reward Accumulated: 133.6398\n",
      "[Ep 36]🎯Reward:5.72|Loss:-1.3990|💊SMILES: CCCNS(=O)(=O)c1ccc(O)c(C(=O)O)c1\n",
      "🎯Total Reward Accumulated: 139.3643\n",
      "[Ep 37]🎯Reward:4.54|Loss:-1.2214|💊SMILES: CC(=O)NCCNC(=O)C(=O)Nc1ccc(F)c(F)c1\n",
      "🎯Total Reward Accumulated: 143.9079\n",
      "[Ep 38]🎯Reward:4.77|Loss:-0.9261|💊SMILES: COCC[C@@](C)(O)CNS(=O)(=O)c1ccccc1\n",
      "🎯Total Reward Accumulated: 148.6765\n",
      "[Ep 39]🎯Reward:2.75|Loss:-0.8250|💊SMILES: Cc1nccc(Cn2c(=O)[nH]c3ccccc3c2=O)n1\n",
      "🎯Total Reward Accumulated: 151.4228\n",
      "[Ep 40]🎯Reward:3.80|Loss:-0.9046|💊SMILES: CC(=O)N1C[C@@H]2OCC(=O)N(Cc3ccccc3)[C@@H]2C1\n",
      "🎯Total Reward Accumulated: 155.2180\n",
      "[Ep 41]🎯Reward:3.80|Loss:-0.8990|💊SMILES: C[C@@H](CNS(C)(=O)=O)Oc1ccccc1O\n",
      "🎯Total Reward Accumulated: 159.0187\n",
      "[Ep 42]🎯Reward:3.73|Loss:-1.0767|💊SMILES: Cn1ccnc1SCC(=O)N1CCCS1(=O)=O\n",
      "🎯Total Reward Accumulated: 162.7489\n",
      "[Ep 43]🎯Reward:2.60|Loss:-0.6306|💊SMILES: COc1cccc(-c2n[nH]c(=S)n(N)c2=O)c1\n",
      "🎯Total Reward Accumulated: 165.3536\n",
      "[Ep 44]🎯Reward:3.82|Loss:-0.8485|💊SMILES: CCS(=O)(=O)[C@@H](CO)[C@@H](O)c1cccc(F)c1\n",
      "🎯Total Reward Accumulated: 169.1706\n",
      "[03:56:14] Explicit valence for atom # 6 B, 4, is greater than permitted\n",
      "[Ep 45]🎯Reward:0.00|Loss:0.0000|💊SMILES: CCOc1cc(B2(N)CCN(C(C)=O)C2)cc(OC)c1\n",
      "🎯Total Reward Accumulated: 169.1706\n",
      "[Ep 46]🎯Reward:4.70|Loss:-1.1363|💊SMILES: C[C@@H](Cc1ccco1)NC(=O)NCCN(C)C(N)=O\n",
      "🎯Total Reward Accumulated: 173.8713\n",
      "[Ep 47]🎯Reward:4.78|Loss:-1.2915|💊SMILES: CCN(CC)C(=O)CN1CCN(Cc2cc(C)on2)CC1\n",
      "🎯Total Reward Accumulated: 178.6536\n",
      "[Ep 48]🎯Reward:4.81|Loss:-1.1759|💊SMILES: CCOC(=O)[C@]1(CN)[C@@H](c2ccccc2)[C@@H]1S(C)(=O)=O\n",
      "🎯Total Reward Accumulated: 183.4623\n",
      "[Ep 49]🎯Reward:4.81|Loss:-1.4361|💊SMILES: C[C@H](C(N)=O)N1CCN(C(=O)NCc2ccco2)CC1\n",
      "🎯Total Reward Accumulated: 188.2729\n",
      "[Ep 50]🎯Reward:3.73|Loss:-1.3148|💊SMILES: COCCC(=O)N1CC(=O)N(C)C2(CCCC2)C1=O\n",
      "🎯Total Reward Accumulated: 192.0041\n",
      "[Ep 51]🎯Reward:3.82|Loss:-0.8464|💊SMILES: CCCn1c(NCC)nc2c1c(=O)[nH]c(=O)n2C\n",
      "🎯Total Reward Accumulated: 195.8203\n",
      "[Ep 52]🎯Reward:3.84|Loss:-0.8422|💊SMILES: COC[C@@](C)(NC(=O)[C@@H]1CCC(=O)N1)c1ccccc1\n",
      "🎯Total Reward Accumulated: 199.6612\n",
      "[Ep 53]🎯Reward:3.48|Loss:-0.9778|💊SMILES: C[C@@]12C=C[C@@H](O1)[C@@H](C(=O)O)[C@@H](C(=O)O)[C@](C)(C(=O)O)C2=O\n",
      "🎯Total Reward Accumulated: 203.1409\n",
      "[Ep 54]🎯Reward:4.86|Loss:-1.2566|💊SMILES: CNC(=O)[C@]1(C)CCCN(Cc2noc(C)n2)C1\n",
      "🎯Total Reward Accumulated: 207.9991\n",
      "[Ep 55]🎯Reward:4.81|Loss:-0.9094|💊SMILES: Cc1n[nH]c([C@@H]2CN(C(=O)C3CC3)CCO2)n1\n",
      "🎯Total Reward Accumulated: 212.8067\n",
      "[Ep 56]🎯Reward:4.74|Loss:-1.1593|💊SMILES: CC(C)[C@H](C(=O)O)N1C(=O)[C@H]2[C@@H]3CC[C@H](O3)[C@@H]2C1=O\n",
      "🎯Total Reward Accumulated: 217.5481\n",
      "[Ep 57]🎯Reward:3.82|Loss:-1.1911|💊SMILES: Cc1cccc(OC[C@@H](C)N2CCS(=O)(=O)CC2)n1\n",
      "🎯Total Reward Accumulated: 221.3696\n",
      "[Ep 58]🎯Reward:5.64|Loss:-1.1219|💊SMILES: COC(=O)[C@H]1CS(=O)(=O)CCN1C(=O)OC(C)(C)C\n",
      "🎯Total Reward Accumulated: 227.0108\n",
      "[Ep 59]🎯Reward:4.77|Loss:-0.9732|💊SMILES: Cc1cc2ncc(C(=O)N3CCN(C)CC3)c(C)n2n1\n",
      "🎯Total Reward Accumulated: 231.7794\n",
      "[Ep 60]🎯Reward:4.79|Loss:-1.3693|💊SMILES: C[C@H](C(N)=O)N1CCC(CN(C)C(=O)N(C)C)CC1\n",
      "🎯Total Reward Accumulated: 236.5717\n",
      "[Ep 61]🎯Reward:4.56|Loss:-1.1114|💊SMILES: CCN(CC)C(=O)CN1C(=O)[C@@H]2[C@H]3C=C[C@@H](C3)[C@H]2C1=O\n",
      "🎯Total Reward Accumulated: 241.1314\n",
      "[Ep 62]🎯Reward:3.77|Loss:-0.7379|💊SMILES: CC(C)NC(=O)NC(=O)COC(=O)c1ccco1\n",
      "🎯Total Reward Accumulated: 244.9009\n",
      "[Ep 63]🎯Reward:4.41|Loss:-1.9138|💊SMILES: COCC[C@H](NC(=O)C(=O)N[C@H]1CC=CCC1)C(=O)OC\n",
      "🎯Total Reward Accumulated: 249.3067\n",
      "[Ep 64]🎯Reward:3.78|Loss:-0.8104|💊SMILES: COC(=O)[C@@]12COC[C@H](Cc3ccccc3)N1C(=O)OC2\n",
      "🎯Total Reward Accumulated: 253.0838\n",
      "[Ep 65]🎯Reward:4.81|Loss:-1.4287|💊SMILES: CN(C)S(=O)(=O)N1CCO[C@@H](c2ccc(F)cn2)C1\n",
      "🎯Total Reward Accumulated: 257.8917\n",
      "[Ep 66]🎯Reward:2.90|Loss:-0.7073|💊SMILES: Cn1cc([C@@H]2C[C@H]2C(=O)Nc2ccc(=O)n(C)c2)cn1\n",
      "🎯Total Reward Accumulated: 260.7924\n",
      "[Ep 67]🎯Reward:4.39|Loss:-2.1779|💊SMILES: CCCCC[C@H](CC)O[C@@H]1OCC(C(=O)O)/C(=O)NC1=O\n",
      "🎯Total Reward Accumulated: 265.1871\n",
      "[Ep 68]🎯Reward:4.73|Loss:-1.1694|💊SMILES: COC(=O)[C@H]1CCCN1C(=O)c1cc2n(n1)CCCO2\n",
      "🎯Total Reward Accumulated: 269.9217\n",
      "[Ep 69]🎯Reward:3.78|Loss:-0.8831|💊SMILES: CCOCC(=O)NCc1nnc2ccc(OCC)nn12\n",
      "🎯Total Reward Accumulated: 273.6986\n",
      "[Ep 70]🎯Reward:4.88|Loss:-1.0715|💊SMILES: CNC(=O)[C@H]1CN(C(=O)c2ccc(Cl)s2)CCO1\n",
      "🎯Total Reward Accumulated: 278.5814\n",
      "[Ep 71]🎯Reward:3.84|Loss:-1.2553|💊SMILES: CCn1cncc1C(=O)NC[C@@H]1CCS(=O)(=O)C1\n",
      "🎯Total Reward Accumulated: 282.4212\n",
      "[Ep 72]🎯Reward:4.83|Loss:-0.9933|💊SMILES: C[C@@H]1CN(C(=O)c2ccc3c(c2)OCC(=O)N3)CCO1\n",
      "🎯Total Reward Accumulated: 287.2477\n",
      "[Ep 73]🎯Reward:3.80|Loss:-1.0477|💊SMILES: CCc1nnc(SCC(=O)NC2CC2)s1\n",
      "🎯Total Reward Accumulated: 291.0434\n",
      "[Ep 74]🎯Reward:4.85|Loss:-1.1075|💊SMILES: COc1ncccc1NC(=O)N1CCN(C)CC1\n",
      "🎯Total Reward Accumulated: 295.8893\n",
      "[Ep 75]🎯Reward:4.81|Loss:-1.2381|💊SMILES: COC(=O)[C@H](O)C1CCN(CCc2ccccn2)CC1\n",
      "🎯Total Reward Accumulated: 300.6991\n",
      "[Ep 76]🎯Reward:3.63|Loss:-0.9356|💊SMILES: CC(=O)Nc1ccc(B(O)OC(C)(C)C(N)=O)cc1\n",
      "🎯Total Reward Accumulated: 304.3293\n",
      "[Ep 77]🎯Reward:3.77|Loss:-0.9550|💊SMILES: CC(=O)N[C@H](C(N)=O)c1nnc2ccccc2n1\n",
      "🎯Total Reward Accumulated: 308.0992\n",
      "[03:57:15] SMILES Parse Error: unclosed ring for input: 'CCS(=O)(=O)[C@H]1[C@H]6c3ccccc3C(=O)[C@@]12O'\n",
      "[Ep 78]🎯Reward:0.00|Loss:0.0000|💊SMILES: CCS(=O)(=O)[C@H]1[C@H]6c3ccccc3C(=O)[C@@]12O\n",
      "🎯Total Reward Accumulated: 308.0992\n",
      "[Ep 79]🎯Reward:4.79|Loss:-1.1878|💊SMILES: CN1OC2(CCN(Cc3ccccc3)CC2)C1=O\n",
      "🎯Total Reward Accumulated: 312.8902\n",
      "[Ep 80]🎯Reward:5.85|Loss:-1.0331|💊SMILES: C[C@@H]1CCCN(C(=O)c2c(C(=O)O)cnn2C)C1\n",
      "🎯Total Reward Accumulated: 318.7403\n",
      "[03:57:21] Can't kekulize mol.  Unkekulized atoms: 10 11 12 13 14 15 16 17 18\n",
      "[Ep 81]🎯Reward:0.00|Loss:0.0000|💊SMILES: COC(=O)[C@@H]1C[C@@H]1C(=O)Nc1nnc2ccccc2c1=O\n",
      "🎯Total Reward Accumulated: 318.7403\n",
      "[03:57:23] SMILES Parse Error: unclosed ring for input: 'CC1(C)[C@@H](C(=O)O)[C@H]1CN(C(=O)OCC)C1(C)CO'\n",
      "[Ep 82]🎯Reward:0.00|Loss:0.0000|💊SMILES: CC1(C)[C@@H](C(=O)O)[C@H]1CN(C(=O)OCC)C1(C)CO\n",
      "🎯Total Reward Accumulated: 318.7403\n",
      "[03:57:25] SMILES Parse Error: unclosed ring for input: 'C[C@@H](CN1CCN(CC1CC1)S(=O)(=O)C1CC1)S(C)(=O)=O'\n",
      "[Ep 83]🎯Reward:0.00|Loss:0.0000|💊SMILES: C[C@@H](CN1CCN(CC1CC1)S(=O)(=O)C1CC1)S(C)(=O)=O\n",
      "🎯Total Reward Accumulated: 318.7403\n",
      "[Ep 84]🎯Reward:4.80|Loss:-1.0601|💊SMILES: CNC(=O)[C@]1(C)CN(C(=O)CN2CCC(C)CC2)CCO1\n",
      "🎯Total Reward Accumulated: 323.5417\n",
      "[03:57:29] Can't kekulize mol.  Unkekulized atoms: 1 13 14\n",
      "[Ep 85]🎯Reward:0.00|Loss:0.0000|💊SMILES: Cc1[nH]c(=O)/c(=C\\c2ccccc2)c2c1NC(=O)CN2\n",
      "🎯Total Reward Accumulated: 323.5417\n",
      "[Ep 86]🎯Reward:4.83|Loss:-1.7057|💊SMILES: C[S@@](=O)c1ccc(CNC(=O)[C@@H]2CCC(=O)N2)cc1\n",
      "🎯Total Reward Accumulated: 328.3755\n",
      "[03:57:33] Can't kekulize mol.  Unkekulized atoms: 2 3 4 15 17 20 21\n",
      "[Ep 87]🎯Reward:0.00|Loss:0.0000|💊SMILES: CCc1cc(N2CCN(C(C)C)CC2)n2c(O)nc(=O)nc2[nH]1\n",
      "🎯Total Reward Accumulated: 328.3755\n",
      "[03:57:36] SMILES Parse Error: unclosed ring for input: 'CN1C[C@@H](C(=O)NC2(C(=O)O)CC(C)(C)C)CC1=O'\n",
      "[Ep 88]🎯Reward:0.00|Loss:0.0000|💊SMILES: CN1C[C@@H](C(=O)NC2(C(=O)O)CC(C)(C)C)CC1=O\n",
      "🎯Total Reward Accumulated: 328.3755\n",
      "[Ep 89]🎯Reward:4.79|Loss:-1.0639|💊SMILES: CN([C@H]1CCCN(c2ncccn2)C1)S(C)(=O)=O\n",
      "🎯Total Reward Accumulated: 333.1674\n",
      "[Ep 90]🎯Reward:3.79|Loss:-1.0940|💊SMILES: C[C@@H]1C[C@@H]1C(=O)NC1CCC(N(C)C(N)=O)CC1\n",
      "🎯Total Reward Accumulated: 336.9568\n",
      "[03:57:41] Can't kekulize mol.  Unkekulized atoms: 4 5 6 7 15 17 18\n",
      "[Ep 91]🎯Reward:0.00|Loss:0.0000|💊SMILES: COC(=O)c1ccc2c(=O)n(CC(=O)O)c(C)cc12\n",
      "🎯Total Reward Accumulated: 336.9568\n",
      "[Ep 92]🎯Reward:3.82|Loss:-0.7709|💊SMILES: CN(Cc1ccccc1)Cc1cc(=O)n(C)c(=O)n1C\n",
      "🎯Total Reward Accumulated: 340.7811\n",
      "[03:57:45] SMILES Parse Error: unclosed ring for input: 'C/C=C/CC1/C(=O)OCCC(=O)OCCO'\n",
      "[Ep 93]🎯Reward:0.00|Loss:0.0000|💊SMILES: C/C=C/CC1/C(=O)OCCC(=O)OCCO\n",
      "🎯Total Reward Accumulated: 340.7811\n",
      "[Ep 94]🎯Reward:4.77|Loss:-1.5041|💊SMILES: COC[C@@H]1CCCN(C(=O)CSc2nccn2C)C1\n",
      "🎯Total Reward Accumulated: 345.5475\n",
      "[03:57:47] Can't kekulize mol.  Unkekulized atoms: 5 6 8 10 11\n",
      "[Ep 95]🎯Reward:0.00|Loss:0.0000|💊SMILES: CCOC(=O)c1c(I)c(N)cn1\n",
      "🎯Total Reward Accumulated: 345.5475\n",
      "[Ep 96]🎯Reward:2.81|Loss:-0.5419|💊SMILES: COC[C@]1(C)NC(=O)N(Cc2ccccc2)C1=O\n",
      "🎯Total Reward Accumulated: 348.3604\n",
      "[03:57:51] SMILES Parse Error: unclosed ring for input: 'C[C@H]1CN(C(=O)COCCOCC2)C[C@@H]1N1CCCC1'\n",
      "[Ep 97]🎯Reward:0.00|Loss:0.0000|💊SMILES: C[C@H]1CN(C(=O)COCCOCC2)C[C@@H]1N1CCCC1\n",
      "🎯Total Reward Accumulated: 348.3604\n",
      "[03:57:52] SMILES Parse Error: unclosed ring for input: 'CCN1CCN(CC(=O)N2CCCCc3cnc[nH]2)CC1'\n",
      "[Ep 98]🎯Reward:0.00|Loss:0.0000|💊SMILES: CCN1CCN(CC(=O)N2CCCCc3cnc[nH]2)CC1\n",
      "🎯Total Reward Accumulated: 348.3604\n",
      "[Ep 99]🎯Reward:3.85|Loss:-1.1874|💊SMILES: CN(C)[C@@H]1CN(C(=O)c2cc3ccccc3[nH]2)C[C@H]1O\n",
      "🎯Total Reward Accumulated: 352.2154\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "Fine-tuned model saved.\n"
     ]
    }
   ],
   "source": [
    "!python RLfinetune.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-10 03:57:55.931752: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744237675.950357  169448 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744237675.955252  169448 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744237675.968356  169448 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744237675.968375  169448 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744237675.968377  169448 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744237675.968379  169448 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "I0000 00:00:1744237678.818259  169448 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4280 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]I0000 00:00:1744237680.503627  169601 cuda_dnn.cc:529] Loaded cuDNN version 90800\n",
      "100%|█████████████████████████████████████████| 100/100 [02:24<00:00,  1.44s/it]\n",
      "[04:00:23] Explicit valence for atom # 3 P, 6, is greater than permitted\n",
      "[04:00:23] SMILES Parse Error: unclosed ring for input: 'CN(C)C(=O)/C=C/CNc1cnn([C@@H]2CC(=O)O)C1'\n",
      "[04:00:23] Can't kekulize mol.  Unkekulized atoms: 1 2 5 14 16\n",
      "[04:00:23] Can't kekulize mol.  Unkekulized atoms: 10 11 12 14 15\n",
      "[04:00:23] Can't kekulize mol.  Unkekulized atoms: 1 2 4\n",
      "[04:00:23] SMILES Parse Error: unclosed ring for input: 'CC1CCN(c2c(N3CCOCC3)CC2)n2ncnc1N'\n",
      "[04:00:23] Can't kekulize mol.  Unkekulized atoms: 1 2 3\n",
      "[04:00:23] Can't kekulize mol.  Unkekulized atoms: 1 2 3 7 8\n",
      "[04:00:23] SMILES Parse Error: extra open parentheses while parsing: CS(=O)(=O)c1ccc(-c2ccc(=O)cc2OCC1=O\n",
      "[04:00:23] SMILES Parse Error: check for mistakes around position 16:\n",
      "[04:00:23] CS(=O)(=O)c1ccc(-c2ccc(=O)cc2OCC1=O\n",
      "[04:00:23] ~~~~~~~~~~~~~~~^\n",
      "[04:00:23] SMILES Parse Error: Failed parsing SMILES 'CS(=O)(=O)c1ccc(-c2ccc(=O)cc2OCC1=O' for input: 'CS(=O)(=O)c1ccc(-c2ccc(=O)cc2OCC1=O'\n",
      "[04:00:23] SMILES Parse Error: unclosed ring for input: 'CN1[Si](C)N(C(=O)CC(F)(F)F)CCN1CC1'\n",
      "[04:00:23] Can't kekulize mol.  Unkekulized atoms: 7 8 9\n",
      "[04:00:23] SMILES Parse Error: extra close parentheses while parsing: CC1(C)O[C@@H]2CO[C@@](CO)[C@@H]2O)OC12CCOCC1\n",
      "[04:00:23] SMILES Parse Error: check for mistakes around position 34:\n",
      "[04:00:23] 2CO[C@@](CO)[C@@H]2O)OC12CCOCC1\n",
      "[04:00:23] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[04:00:23] SMILES Parse Error: Failed parsing SMILES 'CC1(C)O[C@@H]2CO[C@@](CO)[C@@H]2O)OC12CCOCC1' for input: 'CC1(C)O[C@@H]2CO[C@@](CO)[C@@H]2O)OC12CCOCC1'\n",
      "[04:00:23] SMILES Parse Error: unclosed ring for input: 'COC(=O)[C@@]12CCC[C@@H]1CN(CC(=O)OCC1)C2'\n",
      "[04:00:23] Can't kekulize mol.  Unkekulized atoms: 1 2 3\n",
      "[04:00:23] SMILES Parse Error: unclosed ring for input: 'CCCc1nc2c3ccccc3nc2n(CC(N)=O)c(=O)n12'\n",
      "[04:00:23] SMILES Parse Error: unclosed ring for input: 'Cc1ccccc1/C=C1/NC(=O)N=C(N)C1=S\\C(=O)O1'\n",
      "[04:00:23] Can't kekulize mol.  Unkekulized atoms: 3 4 5 6 7 8 9\n",
      "[04:00:23] Can't kekulize mol.  Unkekulized atoms: 6 7 9 10 12\n",
      "[04:00:23] SMILES Parse Error: unclosed ring for input: 'C[C@H]1CCCN(S(=O)(=O)c2cccnc2)[C@@H]1CNCCO1'\n",
      "[04:00:23] Can't kekulize mol.  Unkekulized atoms: 7 8 9 10 11 12 13 14 15\n",
      "[04:00:23] Can't kekulize mol.  Unkekulized atoms: 2 3 4 5 6\n",
      "[04:00:23] SMILES Parse Error: unclosed ring for input: 'C[C@@H]1CC(=O)c2cnc3c(c2C1CCNCCO3)=NNCCN12'\n",
      "[04:00:23] SMILES Parse Error: unclosed ring for input: 'C[C@@H]1C[C@@H](N2CCCCCCC2=N2)CCN1CCO'\n",
      "[04:00:23] SMILES Parse Error: unclosed ring for input: 'COC[C@@]1(CN)CC1(C2)CS(=O)(=O)C1'\n",
      "[04:00:23] SMILES Parse Error: unclosed ring for input: 'CCn1cc(Cl)c(C(=O)N[C@@H]2CCS(=O)(=O)C1)C1'\n",
      "[04:00:23] Can't kekulize mol.  Unkekulized atoms: 3 4 5 6 7 13 14\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:23] DEPRECATION WARNING: please use MorganGenerator\n",
      "[04:00:24] Explicit valence for atom # 3 P, 6, is greater than permitted\n",
      "[04:00:24] SMILES Parse Error: unclosed ring for input: 'CN(C)C(=O)/C=C/CNc1cnn([C@@H]2CC(=O)O)C1'\n",
      "[04:00:24] Can't kekulize mol.  Unkekulized atoms: 1 2 5 14 16\n",
      "[04:00:24] Can't kekulize mol.  Unkekulized atoms: 10 11 12 14 15\n",
      "[04:00:24] Can't kekulize mol.  Unkekulized atoms: 1 2 4\n",
      "[04:00:24] SMILES Parse Error: unclosed ring for input: 'CC1CCN(c2c(N3CCOCC3)CC2)n2ncnc1N'\n",
      "[04:00:24] Can't kekulize mol.  Unkekulized atoms: 1 2 3\n",
      "[04:00:24] Can't kekulize mol.  Unkekulized atoms: 1 2 3 7 8\n",
      "[04:00:24] SMILES Parse Error: extra open parentheses while parsing: CS(=O)(=O)c1ccc(-c2ccc(=O)cc2OCC1=O\n",
      "[04:00:24] SMILES Parse Error: check for mistakes around position 16:\n",
      "[04:00:24] CS(=O)(=O)c1ccc(-c2ccc(=O)cc2OCC1=O\n",
      "[04:00:24] ~~~~~~~~~~~~~~~^\n",
      "[04:00:24] SMILES Parse Error: Failed parsing SMILES 'CS(=O)(=O)c1ccc(-c2ccc(=O)cc2OCC1=O' for input: 'CS(=O)(=O)c1ccc(-c2ccc(=O)cc2OCC1=O'\n",
      "[04:00:24] SMILES Parse Error: unclosed ring for input: 'CN1[Si](C)N(C(=O)CC(F)(F)F)CCN1CC1'\n",
      "[04:00:24] Can't kekulize mol.  Unkekulized atoms: 7 8 9\n",
      "[04:00:24] SMILES Parse Error: extra close parentheses while parsing: CC1(C)O[C@@H]2CO[C@@](CO)[C@@H]2O)OC12CCOCC1\n",
      "[04:00:24] SMILES Parse Error: check for mistakes around position 34:\n",
      "[04:00:24] 2CO[C@@](CO)[C@@H]2O)OC12CCOCC1\n",
      "[04:00:24] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[04:00:24] SMILES Parse Error: Failed parsing SMILES 'CC1(C)O[C@@H]2CO[C@@](CO)[C@@H]2O)OC12CCOCC1' for input: 'CC1(C)O[C@@H]2CO[C@@](CO)[C@@H]2O)OC12CCOCC1'\n",
      "[04:00:24] SMILES Parse Error: unclosed ring for input: 'COC(=O)[C@@]12CCC[C@@H]1CN(CC(=O)OCC1)C2'\n",
      "[04:00:24] Can't kekulize mol.  Unkekulized atoms: 1 2 3\n",
      "[04:00:24] SMILES Parse Error: unclosed ring for input: 'CCCc1nc2c3ccccc3nc2n(CC(N)=O)c(=O)n12'\n",
      "[04:00:24] SMILES Parse Error: unclosed ring for input: 'Cc1ccccc1/C=C1/NC(=O)N=C(N)C1=S\\C(=O)O1'\n",
      "[04:00:24] Can't kekulize mol.  Unkekulized atoms: 3 4 5 6 7 8 9\n",
      "[04:00:24] Can't kekulize mol.  Unkekulized atoms: 6 7 9 10 12\n",
      "[04:00:24] SMILES Parse Error: unclosed ring for input: 'C[C@H]1CCCN(S(=O)(=O)c2cccnc2)[C@@H]1CNCCO1'\n",
      "[04:00:24] Can't kekulize mol.  Unkekulized atoms: 7 8 9 10 11 12 13 14 15\n",
      "[04:00:24] Can't kekulize mol.  Unkekulized atoms: 2 3 4 5 6\n",
      "[04:00:24] SMILES Parse Error: unclosed ring for input: 'C[C@@H]1CC(=O)c2cnc3c(c2C1CCNCCO3)=NNCCN12'\n",
      "[04:00:24] SMILES Parse Error: unclosed ring for input: 'C[C@@H]1C[C@@H](N2CCCCCCC2=N2)CCN1CCO'\n",
      "[04:00:24] SMILES Parse Error: unclosed ring for input: 'COC[C@@]1(CN)CC1(C2)CS(=O)(=O)C1'\n",
      "[04:00:24] SMILES Parse Error: unclosed ring for input: 'CCn1cc(Cl)c(C(=O)N[C@@H]2CCS(=O)(=O)C1)C1'\n",
      "[04:00:24] Can't kekulize mol.  Unkekulized atoms: 3 4 5 6 7 13 14\n",
      "💾 Saved 100 generated SMILES to: generated_smiles_CN.smi\n",
      "🖼️ Saved 74 valid molecule images to: generated_molecules_CN.png\n",
      "\n",
      "🔬 Evaluation Metrics:\n",
      "Total: 100\n",
      "Valid: 74\n",
      "Validity %: 74.00\n",
      "Novelty %: 100.00\n",
      "Target Match %: 0.00\n",
      "Diversity: 0.86\n",
      "Avg QED: 0.74\n"
     ]
    }
   ],
   "source": [
    "!python testRLLSTM.py     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
